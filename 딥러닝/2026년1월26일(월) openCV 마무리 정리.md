# ğŸ“˜ AI í—¬ìŠ¤ì¼€ì–´ & OpenCV í•µì‹¬ ìš”ì•½ ê°€ì´ë“œ

## 1. ì „ì²´ì ì¸ íë¦„ (The Big Picture)

AI ëª¨ë¸ì„ ë§Œë“œëŠ” ê³¼ì •ì€ **"ìš”ë¦¬"**ì™€ ê°™ìŠµë‹ˆë‹¤. ì¢‹ì€ ì¬ë£Œ(ë°ì´í„°)ë¥¼ ì†ì§ˆ(ì „ì²˜ë¦¬)í•´ì„œ, ë ˆì‹œí”¼(ëª¨ë¸)ëŒ€ë¡œ ì¡°ë¦¬(í•™ìŠµ)í•˜ê³ , ì˜ˆìœ ì ‘ì‹œì— ë‹´ì•„(ë°°í¬) ì†ë‹˜ì—ê²Œ ë‚´ë†“ëŠ” ê³¼ì •ì…ë‹ˆë‹¤.

| ë‹¨ê³„ | ì—­í•  | ë¹„ìœ  | ì£¼ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬ |
| :--- | :--- | :--- | :--- |
| **1. ë°ì´í„° ìˆ˜ì§‘** | ì´ë¯¸ì§€ë¥¼ ë¶ˆëŸ¬ì˜¤ê³  í™•ì¸í•˜ê¸° | ì¥ë³´ê¸° | `os`, `glob` |
| **2. ì „ì²˜ë¦¬ (Preprocessing)** | ì´ë¯¸ì§€ë¥¼ ê¹¨ë—í•˜ê³  ì„ ëª…í•˜ê²Œ ë‹¤ë“¬ê¸° | **ì¬ë£Œ ì†ì§ˆ** (ì”»ê³  ê»ì§ˆ ê¹Œê¸°) | **`cv2 (OpenCV)`**, `numpy` |
| **3. ë°ì´í„° ì¦ê°• (Augmentation)** | ë¶€ì¡±í•œ ë°ì´í„°ë¥¼ ì¸ìœ„ì ìœ¼ë¡œ ëŠ˜ë¦¬ê¸° | ì¬ë£Œ ë¶ˆë¦¬ê¸° | `torchvision.transforms`, `albumentations` |
| **4. ëª¨ë¸ í•™ìŠµ (Training)** | íŒ¨í„´ì„ ì°¾ì•„ë‚´ì–´ ê³µë¶€í•˜ê¸° | **ì¡°ë¦¬** (ë“ì´ê³  ë³¶ê¸°) | **`torch (PyTorch)`**, `tensorflow` |
| **5. ì¶”ë¡  ë° ë°°í¬ (Inference)** | ìƒˆë¡œìš´ ì‚¬ì§„ì„ ì§„ë‹¨í•˜ê³  ë‚´ë³´ë‚´ê¸° | ì„œë¹™ & í¬ì¥ | `onnx`, `gradio` |

---

## 2. í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ & ìš©ì–´ ì„¤ëª…

ì½”ë“œë¥¼ ë³¼ ë•Œë§ˆë‹¤ í—·ê°ˆë¦¬ëŠ” ë…€ì„ë“¤ì„ ì •ë¦¬í–ˆìŠµë‹ˆë‹¤.

* **`import cv2` (OpenCV)**
    * **ì—­í• :** **"ì´ë¯¸ì§€ ìš”ë¦¬ì‚¬"**. ìë¥´ê³ , ëŒë¦¬ê³ , ìƒ‰ì„ ë°”ê¾¸ê³ , íë¦¿í•œ ê±¸ ì„ ëª…í•˜ê²Œ ë§Œë“œëŠ” ëª¨ë“  ì¼ì„ í•©ë‹ˆë‹¤.
* **`import numpy as np` (NumPy)**
    * **ì—­í• :** **"ìˆ˜í•™ ê³„ì‚°ê¸°"**. ì»´í“¨í„°ëŠ” ì‚¬ì§„ì„ ê·¸ë¦¼ì´ ì•„ë‹Œ 'ìˆ«ì ë©ì–´ë¦¬(í–‰ë ¬)'ë¡œ ë´…ë‹ˆë‹¤. ì´ ìˆ«ìë“¤ì„ ë¹ ë¥´ê²Œ ê³„ì‚°í•´ ì£¼ëŠ” ë„êµ¬ì…ë‹ˆë‹¤.
* **`import torch` (PyTorch)**
    * **ì—­í• :** **"ì¸ê³µì§€ëŠ¥ ë‡Œ"**. ì‹ ê²½ë§ì„ ë§Œë“¤ê³  í•™ìŠµì‹œí‚¤ëŠ” ë³¸ì²´ì…ë‹ˆë‹¤.
* **`tensor` (í…ì„œ)**
    * **ì„¤ëª…:** **"AI ì „ìš© ë°ì´í„° í¬ì¥ì§€"**. `numpy`ê°€ ì¼ë°˜ì ì¸ ìˆ«ìë¼ë©´, `tensor`ëŠ” AI ëª¨ë¸(GPU) ì•ˆì—ì„œ ìŒ©ìŒ© ë‹¬ë¦´ ìˆ˜ ìˆê²Œ í¬ì¥ëœ ë°ì´í„°ì…ë‹ˆë‹¤.
* **`batch_size` (ë°°ì¹˜ ì‚¬ì´ì¦ˆ)**
    * **ì„¤ëª…:** **"í•œ ì… í¬ê¸°"**. 1,000ì¥ì˜ ì‚¬ì§„ì„ í•œ ë²ˆì— ê³µë¶€ ëª» í•˜ë‹ˆ, 16ì¥ì´ë‚˜ 32ì¥ì”© ë‚˜ëˆ ì„œ ê³µë¶€í•˜ëŠ” ë‹¨ìœ„ì…ë‹ˆë‹¤.
* **`epoch` (ì—í¬í¬)**
    * **ì„¤ëª…:** **"ë¬¸ì œì§‘ íšŒë… ìˆ˜"**. ì „ì²´ ë°ì´í„°ë¥¼ ì²˜ìŒë¶€í„° ëê¹Œì§€ í•œ ë²ˆ í›‘ì–´ë³´ëŠ” ê²ƒì„ 1 ì—í¬í¬ë¼ê³  í•©ë‹ˆë‹¤.

---

## 3. í•µì‹¬ ì½”ë“œ êµ¬í˜„ 

### â‘  í—¬ìŠ¤ì¼€ì–´ íŠ¹í™” ì „ì²˜ë¦¬ (OpenCV)
ì˜ë£Œ ì˜ìƒì—ì„œ ê°€ì¥ ì¤‘ìš”í•œ **ë…¸ì´ì¦ˆ ì œê±°**ì™€ **ì„ ëª…ë„ í–¥ìƒ(CLAHE)** ì½”ë“œì…ë‹ˆë‹¤.

```python
import cv2
import numpy as np
import matplotlib.pyplot as plt

def medical_preprocessing(image_path):
    \"\"\"
    ì˜ë£Œ ì˜ìƒì„ ìœ„í•œ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸
    1. í‘ë°± ë¡œë“œ -> 2. ë…¸ì´ì¦ˆ ì œê±° -> 3. CLAHE(ì„ ëª…í™”) -> 4. í¬ê¸° í†µì¼
    \"\"\"
    # 1. ì´ë¯¸ì§€ ì½ê¸° (ì˜ë£Œ ì˜ìƒì€ ì£¼ë¡œ í‘ë°±)
    # cv2.IMREAD_GRAYSCALE: í‘ë°±ìœ¼ë¡œ ì½ì–´ë¼!
    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
    
    if img is None:
        print("ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤!")
        return None

    # 2. ë…¸ì´ì¦ˆ ì œê±° (Gaussian Blur)
    # ì—‘ìŠ¤ë ˆì´ì˜ ìê¸€ìê¸€í•œ ê¸°ê³„ì  ë…¸ì´ì¦ˆë¥¼ ë¶€ë“œëŸ½ê²Œ ë­‰ê°œì¤ë‹ˆë‹¤.
    # (5, 5): í•„í„° í¬ê¸° (í´ìˆ˜ë¡ ë” ë§ì´ ë­‰ê°œì§)
    img_blurred = cv2.GaussianBlur(img, (5, 5), 0)

    # 3. CLAHE (Contrast Limited Adaptive Histogram Equalization) â˜…ì¤‘ìš”â˜…
    # ë„ˆë¬´ ì–´ë‘¡ê±°ë‚˜ ë°ì€ ê³³ì˜ ëŒ€ë¹„ë¥¼ ë§ì¶°ì„œ ìˆ¨ê²¨ì§„ ë³‘ë³€ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    img_clahe = clahe.apply(img_blurred)

    # 4. í¬ê¸° ì¡°ì • (Resize)
    # AI ëª¨ë¸ì€ ì •í•´ì§„ í¬ê¸°(ì˜ˆ: 224x224)ë§Œ ë¨¹ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    img_resized = cv2.resize(img_clahe, (224, 224))

    return img_resized

# ì‹¤í–‰ ì˜ˆì‹œ (ì´ë¯¸ì§€ ê²½ë¡œë¥¼ ë„£ì–´ì£¼ì„¸ìš”)
# result = medical_preprocessing('my_xray.jpg')
# plt.imshow(result, cmap='gray')
```

### â‘¡ ë°ì´í„° ì¦ê°• ë° ë¡œë” ì„¤ì • (PyTorch)
ë¶€ì¡±í•œ ë°ì´í„°ë¥¼ ëŠ˜ë¦¬ê³ , AIì—ê²Œ ë– ë¨¹ì—¬ ì¤„ ì¤€ë¹„ë¥¼ í•©ë‹ˆë‹¤.

```python
import torch
from torchvision import transforms, datasets
from torch.utils.data import DataLoader

# 1. ë°ì´í„° ì¦ê°• (Augmentation) ì •ì˜
# Compose: ì—¬ëŸ¬ ì‘ì—…ì„ ìˆœì„œëŒ€ë¡œ ë¬¶ëŠ” íŒŒì´í”„ë¼ì¸
healthcare_transforms = transforms.Compose([
    transforms.Resize((224, 224)),        # í¬ê¸° ë§ì¶”ê¸°
    transforms.RandomHorizontalFlip(p=0.5), # 50% í™•ë¥ ë¡œ ì¢Œìš° ë°˜ì „ (ë°ì´í„° 2ë°° íš¨ê³¼)
    transforms.RandomRotation(15),        # ì‚´ì§ íšŒì „ (ìì„¸ê°€ ì‚ëš¤ì–´ì§„ í™˜ì ëŒ€ë¹„)
    transforms.ToTensor(),                # ì´ë¯¸ì§€ë¥¼ ìˆ«ì(0~1) í…ì„œë¡œ ë³€í™˜
    transforms.Normalize([0.5], [0.5])    # ì •ê·œí™” (í•™ìŠµ íš¨ìœ¨ Up)
])

# 2. ë°ì´í„°ì…‹ ì—°ê²° (í´ë” êµ¬ì¡°: data/train/ì •ìƒ, data/train/ì§ˆë³‘)
# train_dir = './data/train'
# train_data = datasets.ImageFolder(train_dir, transform=healthcare_transforms)

# 3. ë°ì´í„° ë¡œë” (ìˆŸê°€ë½)
# train_loader = DataLoader(train_data, batch_size=16, shuffle=True)
```

### â‘¢ ëª¨ë¸ í•™ìŠµ ë° ì €ì¥ (Training Loop)
ì‹¤ì œ ê³µë¶€ë¥¼ ì‹œí‚¤ê³  ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥í•˜ëŠ” í•µì‹¬ ë£¨í”„ì…ë‹ˆë‹¤.

```python
import torch.nn as nn
import torch.optim as optim

def train_model(model, train_loader, device):
    # 1. ë„êµ¬ ì¤€ë¹„
    criterion = nn.CrossEntropyLoss() # ì†ì‹¤í•¨ìˆ˜ (ì±„ì í‘œ: í‹€ë¦° ë§Œí¼ ì ìˆ˜ ê¹ê¸°)
    optimizer = optim.Adam(model.parameters(), lr=0.001) # ìµœì í™” (ê³µë¶€ ì „ëµ: ì ìˆ˜ ì˜¬ë¦¬ê¸°)
    
    model.to(device) # ëª¨ë¸ì„ GPU(ë˜ëŠ” CPU)ë¡œ ì´ë™
    model.train()    # "ê³µë¶€ ëª¨ë“œ ì‹œì‘!"

    # 2. ë°˜ë³µ í•™ìŠµ (1 ì—í¬í¬)
    for images, labels in train_loader:
        images, labels = images.to(device), labels.to(device)

        # ì´ˆê¸°í™” -> ì˜ˆì¸¡ -> ì±„ì  -> ì—­ì „íŒŒ -> ìˆ˜ì •
        optimizer.zero_grad()         # ì´ì „ ê¸°ì–µ ì§€ìš°ê¸°
        outputs = model(images)       # ë¬¸ì œ í’€ê¸° (ì˜ˆì¸¡)
        loss = criterion(outputs, labels) # ì±„ì  (ì†ì‹¤ ê³„ì‚°)
        loss.backward()               # ì˜¤ë‹µ ë…¸íŠ¸ ì‘ì„± (ì—­ì „íŒŒ)
        optimizer.step()              # ì‹¤ë ¥ í‚¤ìš°ê¸° (ê°€ì¤‘ì¹˜ ìˆ˜ì •)
        
    print("í•œ ë²ˆì˜ í•™ìŠµ(Epoch)ì´ ëë‚¬ìŠµë‹ˆë‹¤.")

    # 3. ëª¨ë¸ ì €ì¥ (ì¤‘ìš”!)
    # í•™ìŠµëœ ì§€ì‹ì„ .pth íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
    torch.save(model.state_dict(), 'my_healthcare_model.pth')
    print("ëª¨ë¸ ì €ì¥ ì™„ë£Œ!")
```

### â‘£ ONNX ë‚´ë³´ë‚´ê¸° (Export)
í•™ìŠµëœ ëª¨ë¸ì„ ë³‘ì› ì–´ë””ì„œë“  ì“¸ ìˆ˜ ìˆê²Œ í‘œì¤€ í¬ë§·ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

```python
import torch.onnx

def export_onnx(model, save_path='model.onnx'):
    model.eval() # "í‰ê°€ ëª¨ë“œ" (ì ˆëŒ€ ìŠì§€ ë§ê¸°!)
    model.cpu()  # ë³´í†µ ë³€í™˜ì€ CPUì—ì„œ í•©ë‹ˆë‹¤.
    
    # ë”ë¯¸ ë°ì´í„° (ë§ˆë£¨íƒ€) ìƒì„±: ëª¨ë¸ ì…êµ¬ í¬ê¸°ì™€ ë˜‘ê°™ì´ ë§Œë“­ë‹ˆë‹¤.
    # (ë°°ì¹˜í¬ê¸° 1, ì±„ë„ 3(RGB), ì„¸ë¡œ 224, ê°€ë¡œ 224)
    dummy_input = torch.randn(1, 3, 224, 224)

    torch.onnx.export(
        model,
        dummy_input,
        save_path,
        export_params=True,      # ê°€ì¤‘ì¹˜ í¬í•¨
        opset_version=12,        # OpenCV í˜¸í™˜ì„± ì¢‹ì€ ë²„ì „ â˜…
        do_constant_folding=True,# ìµœì í™”
        input_names=['input'],
        output_names=['output']
    )
    print(f"ONNX ë³€í™˜ ì™„ë£Œ: {save_path}")
```

---
