# 머신러닝 4일차 정리 (분류 모델 & 평가 지표)

> 분류(Classification) 문제의 전체 흐름과  
> KNN, 로지스틱 회귀, 나이브 베이즈, 의사결정나무,  
> 그리고 성능 평가 지표(Confusion Matrix, Precision, Recall, F1)를 정리한다.

---

## 1. 분류 문제란?

- **정답이 범주형(label)** 인 문제
- 예시
  - 유방암 여부 (암 / 정상)
  - 당뇨 여부 (0 / 1)
  - 스팸 메일 (스팸 / 정상)

👉 결과는 **숫자처럼 보이지만 의미는 범주**

---

## 2. 분류 모델의 공통 구조

```text
입력 데이터(X)
 → 분류 모델 (KNN, Logistic, Tree 등)
 → 예측값(y_pred: 클래스)

fit(X_train, y_train) : 학습
predict(X) : 클래스 예측
predict_proba(X) : 확률 예측

3. 주요 분류 모델 정리
3.1 KNN (K-Nearest Neighbors)

거리 기반 모델

새로운 데이터 주변의 K개 이웃을 보고 다수결

특징

스케일링 필수 (StandardScaler)

학습 개념 거의 없음

데이터 많아지면 느림

언제 쓰나?

간단한 기준선 모델

데이터 구조가 직관적일 때

3.2 로지스틱 회귀 (Logistic Regression)

선형 모델 + 확률 기반

시그모이드 함수 사용

특징

확률 해석 가능

해석력 좋음

선형 관계 가정

3.3 나이브 베이즈 (Naive Bayes)

확률 기반 모델

변수들이 서로 독립이라고 가정 (Naive)

특징

매우 빠름

데이터 적어도 잘 동작

텍스트 분류에 강함

단점

독립 가정이 현실과 안 맞는 경우 많음

3.4 의사결정나무 (Decision Tree)

질문을 반복하며 데이터를 분기

규칙 기반 모델

주요 파라미터

criterion: gini / entropy

max_depth: 트리 깊이

min_samples_leaf: 리프 최소 샘플 수

특징

해석 쉬움

스케일링 불필요

과적합 위험 큼

4. 분류 평가의 핵심 뼈대: Confusion Matrix
                실제
            0(음성)   1(양성)
예측 0       TN        FN
예측 1       FP        TP
TN: 정상 → 정상
TP: 질병 → 질병
FP: 정상 → 질병 (오진)
FN: 질병 → 정상 (놓침, 가장 위험)

5. 성능 평가 지표 정리
5.1 Accuracy (정확도)
(TP + TN) / 전체


전체 중 맞춘 비율

불균형 데이터에서 위험

5.2 Precision (정밀도)
TP / (TP + FP)


양성이라고 예측한 것 중 진짜 양성

오진(FP)이 중요한 문제에 중요

예: 스팸 필터

5.3 Recall (재현율)
TP / (TP + FN)


실제 양성 중 얼마나 잡았는가

FN이 위험한 문제에서 최우선

예: 의료(암, 당뇨)

5.4 F1-score
Precision과 Recall의 조화 평균


두 지표의 균형

불균형 데이터에서 Accuracy보다 신뢰도 높음

| 개념                   | 정리                  |
| -------------------- | ------------------- |
| predict(X)에 X만 넣는 이유 | y는 예측 대상            |
| fit vs fit_transform | 전처리에서만 transform 필요 |
| 가중치 크기               | 크기 자체보다 **부호와 맥락**  |
| 수치 크기 비교             | 모델/지표마다 기준 다름       |
| Accuracy 높음          | 좋은 모델이 아닐 수도 있음     |

오늘 배운 핵심 한 줄 요약

분류 문제는 모델보다
평가 기준(무엇을 놓치면 안 되는가)을 먼저 정하는 것이 중요하다.
