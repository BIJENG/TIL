# 머신러닝 심화 1일차 정리 (Clustering & Advanced ML)

> 목적  
> - 기초 머신러닝에서 한 단계 더 나아가  
> - **군집화 심화 + 모델을 제대로 쓰는 방법**을 이해하는 날

---

## 1. 오늘 배운 전체 큰 흐름

데이터 전처리
→ 스케일링(StandardScaler)
→ (PCA)
→ 군집화 알고리즘
→ 군집 성능 평가
→ 해석

지도학습 심화
→ Feature Engineering
→ 교차검증(CV)
→ 고급 모델(SVM, Ensemble)
→ 설명 가능한 AI(XAI)


📌 오늘은 **군집화 심화 + 이후 지도학습 심화 개요**가 핵심

---

## 2. 군집화(Clustering) 기본 개념 복습

- 비지도 학습 (정답 없음)
- 비슷한 데이터끼리 자동으로 묶음
- 목표: **패턴 발견, 데이터 구조 이해**

### 분류 vs 군집화
| 구분 | 분류 | 군집화 |
|---|---|---|
| 정답 | 있음 | 없음 |
| 기준 | 사람이 정함 | 모델이 스스로 |
| 평가 | Accuracy, F1 | Silhouette |

> **군집화 = 정답을 만드는 문제**

---

## 3. 군집화 알고리즘 3종 (심화 핵심)

### 3-1. Mean Shift

**개념**
- 데이터가 많이 몰린 방향(밀도 봉우리)을 찾아 군집 생성
- 군집 개수 자동 결정

**핵심 파라미터**
- `bandwidth (h)` ⭐⭐⭐

**의미**
- 밀도를 계산하는 반경
- h ↑ → 군집 합쳐짐
- h ↓ → 군집 세분화

**실습 포인트**
- `estimate_bandwidth(quantile=...)`
- quantile ↓ → h ↓ → 군집 수 증가

📌 Diabetes 데이터에서 군집 1개 나온 이유  
→ 연속 분포 + 밀도 봉우리 1개  
→ **정상적인 결과**

---

### 3-2. DBSCAN

**개념**
- 밀도 기반 군집화
- 군집이 안 되는 점은 **Noise(-1)** 로 분류

**핵심 파라미터**
- `eps` ⭐⭐⭐ : 이웃으로 인정하는 거리
- `min_samples` : 최소 이웃 수

**eps 변화 효과**
- eps ↓ → 노이즈 증가
- eps ↑ → 노이즈 감소

📌 **Noise ≠ 일반적인 이상치**
- 이상치: 값 기준
- Noise: **주변에 이웃이 없는 점**

**K-Distance Plot**
- eps 결정용 그래프
- 꺾이는 지점(elbow)의 y값 사용

---

### 3-3. GMM (Gaussian Mixture Model)

**개념**
- 데이터를 여러 개의 가우시안 분포로 가정
- 확률 기반 **Soft Clustering**

**핵심 파라미터**
- `n_components` ⭐⭐⭐ : 군집(분포) 개수

**특징**
- 각 데이터는 여러 군집에 확률로 소속
- 경계가 부드러움

```python
gmm.predict_proba(X)

4. 군집화 성능 평가
Silhouette Score ⭐⭐⭐

의미

같은 군집은 가깝고

다른 군집은 멀수록 좋음

범위

-1 ~ 1

1에 가까울수록 좋음
| 점수        | 해석          |
| --------- | ----------- |
| 0.7 이상    | 매우 좋음       |
| 0.5 ~ 0.7 | 괜찮음         |
| 0.3 ~ 0.5 | 애매하지만 의미 있음 |
| 0 이하      | 잘못된 군집      |

5. ★ 헷갈렸던 개념 정리 (중요)
★ 노이즈 vs 이상치

이상치: 통계적 기준

노이즈(DBSCAN): 밀도 기준

★ 왜 Diabetes 데이터는 군집이 잘 안 나왔나?

회귀용 데이터

연속적인 분포

명확한 군집 구조 없음

👉 군집 1개 or 노이즈 변화만 있는 게 정상

| 알고리즘       | 핵심 파라미터      | 의미      |
| ---------- | ------------ | ------- |
| Mean Shift | bandwidth(h) | 밀도 반경   |
| DBSCAN     | eps          | 이웃 거리   |
| GMM        | n_components | 가우시안 개수 |

6. 군집화 실습을 3개나 한 이유

군집화도 관점이 다르다

Mean Shift
→ “어디가 제일 붐비는가?”

DBSCAN
→ “이 점은 무리에 속하는가?”

GMM
→ “어느 군집일 확률이 얼마나 되는가?”

👉 같은 데이터도 관점에 따라 결과가 달라짐

7. 지도학습 심화 개념 (개요)
Feature Engineering

의미 있는 변수 생성

성능에 가장 큰 영향

교차검증 (Cross Validation)

데이터 여러 번 나눠 평가

과적합 방지

SVM

마진 최대화 분류기

스케일링 필수

앙상블

여러 모델 결합

RandomForest, XGBoost

XAI (SHAP)

왜 이런 예측이 나왔는지 설명

헬스케어에서 필수

8. 오늘의 핵심 한 줄 요약

머신러닝 심화 1일차는
“모델을 돌리는 단계”에서
“모델을 이해하고 조정하고 설명하는 단계”로 넘어가는 날이다
