# 머신러닝 기초 Day 1~3 정리 (EDA → 전처리 → 지도학습(회귀) → 평가지표 → L1/L2)

> 오늘 목표:  
> “데이터를 왜 먼저 보고(EDA), 왜 전처리하고, 그 다음 회귀로 학습시키고, 어떤 지표로 평가하는지” 흐름으로 이해하기  
> + L1/L2 정규화(릿지/라쏘) 실습까지 연결

---

## 1) EDA란?

EDA(Exploratory Data Analysis)는 한마디로:

> **“이 데이터가 어떻게 생겼는지, 믿을 수 있는지, 학습에 쓸 만한지 확인하는 단계”**

### 헬스케어 데이터에서 EDA가 특히 중요한 이유
AI 헬스케어 맥락에서는:
- 측정 오류가 많음 (혈압, 혈당 등)
- 결측치가 많음 (검사 안 한 항목)
- 환자별 편차가 큼
- 이상치가 **노이즈가 아니라 질병 신호**일 수도 있음

👉 그래서 EDA는 단순 “통계 보기”가 아니라  
**의학적 의미를 고려하면서 데이터 품질을 판단하는 과정**이 된다.

---

## 2) 전처리(Preprocessing)란?

> **모델에 넣기 전에 데이터의 문제(결측/이상/스케일/인코딩 등)를 정리해서 학습 가능하게 만드는 과정**

대표 예시:
- 결측치 처리: 제거 / 평균·중앙값 대치 / 모델 기반 대치
- 이상치 처리: 제거 / 클리핑 / 원인 분석(질병 신호 가능성)
- 스케일링: StandardScaler / MinMaxScaler
- 범주형 인코딩: one-hot / label encoding

---

## 3) 문제 유형: 회귀 vs 분류 (가장 중요한 기준)

✅ 핵심 기준은 **예측하려는 타겟(y)의 형태**다.

- **회귀(Regression)**: y가 **연속형 숫자** (예: 혈당, 집값, 수축기혈압)
- **분류(Classification)**: y가 **범주/라벨** (예: 당뇨 여부 0/1, 질병 종류 A/B/C)

> 입력 X가 숫자/텍스트/이미지든 상관없고  
> **결정권은 y가 가진다.**

---

## 4) “통계적 회귀” vs “머신러닝 회귀” 관점 차이

선형회귀는 목적에 따라 접근이 달라진다.

| 구분 | 통계적 회귀 분석 | 머신러닝(예측 중심) |
|---|---|---|
| 주요 목표 | 해석(Interpretation) | 예측(Prediction) |
| 관심 포인트 | 계수 의미, p-value, 가정 충족 | 성능 지표(RMSE/MAE/R²), 일반화 |
| 변수 처리 | 다중공선성 회피 중요 | 상관관계가 있어도 예측 되면 OK (단, 과적합 주의) |
| 핵심 | 가정(선형성/독립성/등분산성/정규성) 중요 | 가정보다 **검증 성능**이 우선 |

---

## 5) “학습”이란 무엇인가?

> **예측을 만들고 → 오차를 계산하고 → 오차가 줄어들도록 파라미터(가중치)를 반복 업데이트하는 과정**

즉,
1) 예측값 계산 (Forward)  
2) 오차 계산 (Loss)  
3) 오차 줄이도록 업데이트 (Optimization)

---

## 6) 회귀 평가지표: MAE / MSE / RMSE / R² / Adjusted R²

### ⚠️ 중요한 오해 수정
❌ “회귀에는 3가지 방법이 있다(MAE/MSE/RMSE)”  
✅ 정확히는:

> **회귀 모델은 하나(학습 방식)이고,  
> MAE/MSE/RMSE는 그 결과(예측)를 평가하는 ‘지표’다.**

---

### (1) MAE (Mean Absolute Error)
- 오차의 절댓값 평균  
- 큰 오차/작은 오차를 **동일하게** 취급  
- 해석이 직관적

✅ 언제 쓰나?
- 일반적인 예측
- “평균적으로 얼마나 틀리는지”가 중요할 때

---

### (2) MSE (Mean Squared Error)
- 오차를 제곱해서 평균  
- 큰 오차에 **강한 벌점**  
- 단위가 제곱 단위로 바뀌어 해석이 불편

✅ 언제 쓰나?
- 모델 학습/비교 내부에서 많이 사용
- 큰 오차를 강하게 벌주고 싶을 때

---

### (3) RMSE (Root Mean Squared Error)
- MSE에 제곱근을 씌움  
- 큰 오차에 민감(=MSE 성격 유지)  
- 단위를 원래 y 단위로 되돌려 해석 쉬움

✅ 언제 쓰나?
- 의료/금융처럼 큰 실수가 치명적일 때

---

### MAE vs RMSE 선택 기준 (실무 감각)
- **MAE**: 오차 크기를 고르게 보자 (일반 예측)
- **RMSE**: 큰 오차가 치명적이다 (의료 수치/리스크)

---

## 7) 제곱/제곱근/로그의 의미

- **제곱(Squared)**: 큰 오차를 더 크게 만들어 벌점 강화  
- **제곱근(√)**: 제곱 때문에 커진 값을 **원래 단위로 복원**  
- **로그(log)**: 값의 범위를 **의도적으로 압축(스케일 줄이기)**

---

## 8) R²(결정계수)와 음수 문제

### R² 의미
> **“평균만 예측하는 모델(베이스라인)보다 얼마나 더 잘 설명하나”**

수식 느낌(개념):
- 평균 모델 오차 대비, 내 모델 오차가 얼마나 줄었나를 보는 값

### R² 범위
- 보통 0~1 사이에서 많이 나오지만,
- ✅ **테스트 성능이 평균 모델보다 못하면 음수도 가능**

즉 R² < 0이면:
> **“이 모델은 평균값 찍는 것보다도 못하다”**

---

## 9) Adjusted R²(수정된 결정계수)

> **변수(p)가 늘어나면 R²가 ‘자동으로’ 올라가는 경향이 있어서, 그 증가를 벌점으로 보정한 지표**

- 변수를 마구 늘려도 “좋아 보이는 착시”를 막는 용도
- **모델 비교(특히 선형 회귀에서 변수 수가 다를 때)**에 유용

⚠️ 주의:
- Adjusted R²는 보통 **훈련 데이터 기준**에서 비교할 때 더 의미가 있다.
- 작은 데이터(표본이 너무 적음)에서는 값이 불안정해질 수 있다.

---

## 10) “변수 늘리면 R²가 왜 올라가요?”

핵심은:
- 변수를 추가하면 모델이 데이터를 더 잘 맞출 “자유도”가 늘어남
- 그래서 훈련 기준 R²는 거의 항상 올라가는 방향(또는 유지)

하지만:
- 늘린 변수가 의미 없는 변수면
  - 테스트 성능은 오히려 떨어질 수 있음(과적합)

---

## 11) L1 / L2는 “회귀 방법”이 아니라 “정규화(규제) 옵션”

✅ 정리:
- 회귀 모델(선형회귀)은 기본 뼈대
- L1/L2는 그 위에 붙는 **과적합 방지 장치(규제, regularization)**

### L2 정규화 = Ridge
- 계수를 0으로 만들진 않음
- 대신 전체 계수를 작게 줄여서 안정화(Shrinkage)

### L1 정규화 = Lasso
- 일부 계수를 **정확히 0으로** 만들어 변수를 제거(Feature Selection)

---

## 12) alpha는 무엇인가?

> **정규화 강도(벌점의 세기)를 조절하는 다이얼**

- alpha ↑ : 규제 강해짐 → 모델 단순해짐 → **과소적합 위험↑**
- alpha ↓ : 규제 약해짐 → 선형회귀에 가까워짐

실습에서 Lasso(alpha=1.0)가 성능이 나빠졌던 이유:
- alpha가 커서 중요한 변수까지 0으로 밀어버림 → 과소적합

---

## 13) 과소적합(Underfitting)

> **모델이 너무 단순해서 패턴을 못 배우는 상태**

특징:
- Train 성능도 나쁨
- Test 성능도 나쁨

원인 예:
- alpha 너무 큼 (L1/L2 너무 강함)
- 모델이 너무 단순
- 유용한 특징(feature)이 부족

---

## 14) 스케일링(StandardScaler)은 왜 L1/L2에 중요할까?

Ridge/Lasso는 **계수 크기에 벌점**을 주기 때문에,
변수 단위가 제각각이면:
- 큰 단위 변수는 불리
- 작은 단위 변수는 유리
→ 정규화가 왜곡됨

그래서 보통:
- StandardScaler로 스케일을 맞춘 뒤
- Ridge/Lasso 적용

✅ 올바른 습관
- scaler.fit_transform은 **train만**
- scaler.transform은 **test만**  
(데이터 누수 방지)

---

## 15) sklearn 데이터셋: load_ vs fetch_

- `load_*` : 로컬에 내장된 작은 데이터(즉시 사용)
- `fetch_*` : 처음 한 번 다운로드 후 캐시 사용(더 큰 데이터)

예: `fetch_california_housing()`은 회귀(y가 집값) 실습에 적합

---

## 16) Linnerud로 R²가 “미친 듯이” 나빴던 이유(오늘의 교훈)

- 샘플 수가 매우 작음(20개)
- test split 하면 테스트가 4개 수준 → R²가 매우 불안정
- 타겟(Weight/Waist/Pulse) 중 일부는 X와 관계가 약함
- 그래서 R² 음수 크게 나오는 게 가능

👉 그래서 회귀+정규화 실습은 **California Housing처럼 큰 데이터가 안정적**이었다.

---

## 17) 오늘 실습 결론 (캘리포니아 하우징)

- Linear RMSE ≈ Ridge RMSE (데이터가 충분히 안정적)
- Lasso는 alpha 설정에 따라 성능이 크게 변함  
  (alpha가 크면 변수 많이 제거 → 과소적합 → RMSE 상승)

---

## 보완하면 좋은 다음 목표
- Ridge/Lasso에서 alpha를 여러 값으로 바꿔가며 RMSE/R² 비교
- Pipeline으로 `StandardScaler + 모델` 한 번에 묶기
- 교차검증(CV)로 alpha 최적값 찾기
- 계수(coef_)를 표로 정리해서 “L1은 0이 생기고, L2는 전체가 줄어든다” 시각적으로 확인

---
